---
layout: post
title:  "6. 비지도 학습"
date:   2024-08-27 16:12:30 +09:00
categories: ['ML기초세션']
---
## 1. 군집 학습

**비지도 학습(Unsupervised Learning)** 의 가장 큰 특징은 타깃이 필요하지 않다는 것이다.  
즉 사람에 의해 직접적으로 지도되지 않는다고 이해할 수 있다.

## 1-1. 이미지 분석
아래의 예시를 통해 비지도 학습의 한 종류인 군집 학습에 대해 살펴보자.

 ```python
 plt.imshow(fruits[0], cmap='gray')
plt.show()
```
![alt text](/assets/images/6-image.png)

위와 같이 100*100픽셀의 과일사진 300장이 fruits에 담겨있다. 흑백 사진인 만큼 각 픽셀은 0~255까지의 정숫값을 가진다. 참고로 0에 가까울 수록 검은색이다.
```python
plt.imshow(fruits[0], cmap='gray_r')
plt.show()
```
![alt text](/assets/images/6-image-1.png)

cmap파라미터를 조정할 경우, 흑백이 반전된 상태로도 이미지를 확인할 수 있다.   
이 그림에서는 검은 부분이 픽셀값이 크다고 이해할 수 있다.
```python
fig, axs = plt.subplots(1, 2)
axs[0].imshow(fruits[100], cmap='gray_r')
axs[1].imshow(fruits[200], cmap='gray_r')
plt.show()
```
![alt text](/assets/images/6-image-2.png)

나머지 과일에 대해서도 이미지를 확인할 수 있다. 이때, 위 코드에서 쓰인 subplot은 matplot의 시각화 함수로, 각 그래프를 배치할 (행,열)의 그림판을 만들어 준다고 이해하면 좋다. 

## 1-2. 픽셀값 분석
우리는 여러개의 feature를 통해 무언의 모델을 학습시키는 것을 많이 해왔다. 그렇다면 과연 이미지 학습에서 feature는 무엇일까? 예상할 수 있듯이 각 픽셀이다.

우리는 이를 위해 100*100이라는 2차원 평면을 길이가 10000인 1차원 배열로 바꿀 것이다.
```python
apple = fruits[0:100].reshape(-1, 100*100)
pineapple = fruits[100:200].reshape(-1, 100*100)
banana = fruits[200:300].reshape(-1, 100*100)

print(apple.shape)
#(100, 10000)
```

결과적으로, 각 과일 데이터는 100개의 10000이라는 길이의 배열로 변환되었다!

이후 각 과일들의 픽셀에 담긴 값을 확인해 보자.

```python
print(apple.mean(axis=1))
#[ 88.3346  97.9249  87.3709  98.3703  92.8705  82.6439  94.4244  95.5999
#  90.681   81.6226  87.0578  95.0745  93.8416  87.017   97.5078  87.2019
#  88.9827 100.9158  92.7823 100.9184 104.9854  88.674   99.5643  97.2495
#  94.1179  92.1935  95.1671  93.3322 102.8967  94.6695  90.5285  89.0744
#  97.7641  97.2938 100.7564  90.5236 100.2542  85.8452  96.4615  97.1492
#  90.711  102.3193  87.1629  89.8751  86.7327  86.3991  95.2865  89.1709
#  96.8163  91.6604  96.1065  99.6829  94.9718  87.4812  89.2596  89.5268
#  93.799   97.3983  87.151   97.825  103.22    94.4239  83.6657  83.5159
# 102.8453  87.0379  91.2742 100.4848  93.8388  90.8568  97.4616  97.5022
#  82.446   87.1789  96.9206  90.3135  90.565   97.6538  98.0919  93.6252
#  87.3867  84.7073  89.1135  86.7646  88.7301  86.643   96.7323  97.2604
#  81.9424  87.1687  97.2066  83.4712  95.9781  91.8096  98.4086 100.7823
# 101.556  100.7027  91.6098  88.8976]
```
총 100개의 값이 나왔다. 이를 조금 더 자세하게 살펴보자. 여기서 mean값이 100이 나온이유는, 정확히 말하면 axis=1때문이다. **axis**라는 인수는 굉장히 많이 등장하는데, 이것은 행렬에 대한 연산을 어느 축을 기준으로 진행할 것인지를 결정하는 것이다.

지금 위의 데이터는 행이 100개, 열이 10000개이다. axis=1은 열 방향으로 계산을 하겠다는 의미이다. 즉 다시말해 결과값의 개수가 행의 개수와 동일해야한다는 것이다. 반대로 axis=0이라면 행 방향의 계산을 의미해, 위의 예시에서는 아마 각 픽셀에 대한 평균을 의미하는 10000개의 평균값이 나왔을 것이다.

다시 본론으로 돌아와 해당 과일들의 히스토그램을 확인하자.
```python
plt.hist(np.mean(apple, axis=1), alpha=0.8)
plt.hist(np.mean(pineapple, axis=1), alpha=0.8)
plt.hist(np.mean(banana, axis=1), alpha=0.8)
plt.legend(['apple', 'pineapple', 'banana'])
plt.show()
```

![alt text](/assets/images/6-image-3.png)

이것은 전체 픽셀의 평균에 대한 분포이다. 바나나는 구분이 되나, 파인애플과 사과는 구분이 되지않는다.    
즉 전체 픽셀의 평균으로 군집화 시키기는 어려워 보인다.

이번에는 그렇다면 각 픽셀에 대한 평균을 확인해보겠다. (axis=0) 
```python
fig, axs = plt.subplots(1, 3, figsize=(20, 5))
axs[0].bar(range(10000), np.mean(apple, axis=0))
axs[1].bar(range(10000), np.mean(pineapple, axis=0))
axs[2].bar(range(10000), np.mean(banana, axis=0))
plt.show()
```
![alt text](/assets/images/6-image-4.png)

무언가 픽셀 단위로 보니, 특정한 형상들이 과일마다 보이는 것 같다!    
그렇다면 이 1차원 배열을 2차원으로 바꿔보아도 특정한 형상이 보이지 않을까?
```python
apple_mean = np.mean(apple, axis=0).reshape(100, 100)
pineapple_mean = np.mean(pineapple, axis=0).reshape(100, 100)
banana_mean = np.mean(banana, axis=0).reshape(100, 100)

fig, axs = plt.subplots(1, 3, figsize=(20, 5))
axs[0].imshow(apple_mean, cmap='gray_r')
axs[1].imshow(pineapple_mean, cmap='gray_r')
axs[2].imshow(banana_mean, cmap='gray_r')
plt.show()
```
![alt text](/assets/images/6-image-6.png)
우리가 아는 과일들의 형상이 보이는 것 같다. 이를 활용하면 될 것 같다!

### 1-3. 평균값과 가까운 이미지 고르기

```python
abs_diff = np.abs(fruits - apple_mean)
abs_mean = np.mean(abs_diff, axis=(1,2))
print(abs_mean.shape)
#(300,)
apple_index = np.argsort(abs_mean)[:100]
fig, axs = plt.subplots(10, 10, figsize=(10,10))
for i in range(10):
    for j in range(10):
        axs[i, j].imshow(fruits[apple_index[i*10 + j]], cmap='gray_r')
        axs[i, j].axis('off')
plt.show()
```
![alt text](/assets/images/6-image-5.png)

사과 픽셀들의 평균과 오차가 작은 이미지 100개를 시각화하였더니 모두 사과 이미지가 나왔다! 성공적으로 우리가 원하는 바를 이룬 것이다. 이렇게 비슷한 샘플끼리 모으는 과정을 **군집(Clustering)** 이라고 하고, 이렇게 만들어진 그룹을 **Cluster**라고 부른다.

## 2. k-means
우리가 간과한 사실이 있다. 이전에 분류에서 우리는 이미지들이 바나나, 사과, 파인애플로 분류될 것을 알고있었다. 진정한 비지도 학습이라면 이것조차 우리는 알아서는 안된다.

이를 위해 이번에는 **k-means 군집** 분석을 진행할 것이다. 특정 군집의 평균이자 중심을 찾아 이를 바탕으로 군집화를 하는 것이다. 이때 이 중심을 우리는 Centroid라고 부른다.

알고리즘의 작동방식은 아래와 같다.   
1. 무작위로 k개의 클러스터 중심을 정한다.
2. 각 샘플에서 가장 가까운 클러스터 중심을 찾아 해당 클러스터의 샘플로 지정한다.
3. 클러스터에 속한 샘플의 평균값으로 Centroid를 수정한다.
4. Centroid 변화가 없을 때까지 2-3을 반복한다.


![alt text](/assets/images/6-image-7.png)
### 2-1. sklearn을 통한 구현
실제 sklearn을 통해 k-means clustering을 구현해 보자.

```python
import numpy as np

fruits = np.load('fruits_300.npy')
fruits_2d = fruits.reshape(-1, 100*100)
from sklearn.cluster import KMeans

km = KMeans(n_clusters=3, random_state=42)
km.fit(fruits_2d)
```
n_cluster를 통해 3개의 군집으로 만들 것을 지정했다. 또한 이러한 과정을 통해 나눠진 군집은 labels_ 배열을 통해 확인이 가능하다.
```python
print(km.labels_)
#[2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
# 2 2 2 2 2 0 2 0 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 2 0 2
# 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0
# 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
# 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
# 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
# 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
# 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
# 1 1 1 1]
print(np.unique(km.labels_, return_counts=True))
#(array([0, 1, 2], dtype=int32), array([111,  98,  91]))
```

총 300개의 이미지가 0,1,2 중 하나로 군집화 되었다! 여기서 중요한 점은 군집화에서 레이블 값인 0,1,2는 아무 의미가 없다. 그저 분류를 위한 숫자일 뿐이다. 그리고 실제 그 레이블이 무엇인지 확인하는 것은 이 문제에서는 직접 이미지를 출력해 보는 것이다!
```python
import matplotlib.pyplot as plt

def draw_fruits(arr, ratio=1):
    n = len(arr)    # n은 샘플 개수입니다
    # 한 줄에 10개씩 이미지를 그립니다. 샘플 개수를 10으로 나누어 전체 행 개수를 계산합니다.
    rows = int(np.ceil(n/10))
    # 행이 1개 이면 열 개수는 샘플 개수입니다. 그렇지 않으면 10개입니다.
    cols = n if rows < 2 else 10
    fig, axs = plt.subplots(rows, cols,
                            figsize=(cols*ratio, rows*ratio), squeeze=False)
    for i in range(rows):
        for j in range(cols):
            if i*10 + j < n:    # n 개까지만 그립니다.
                axs[i, j].imshow(arr[i*10 + j], cmap='gray_r')
            axs[i, j].axis('off')
    plt.show()

draw_fruits(fruits[km.labels_==0]) # 불리언 인덱싱
```
![alt text](/assets/images/6-image-9.png)

잘 군집화가 된 것 처럼 보인다. 하지만 km.labels_==2일때는 상황이 조금 다르다. 
![alt text](/assets/images/6-image-10.png)

**정확하게 순도 100%로 군집화되지 못했음**을 알 수 있다.   
하지만 그렇다고 하더라고 타깃 레이블 없이 군집화가 이정도로 이루어진다는 점이 주목할만 하다.

### 2-2. Centroid
아까처럼 각 픽셀의 평균을 통해 각 군집의 **평균적인 형상**을 확인해 보자.   
평균, 즉 Centroid는 **cluster_centers_** 에 저장되어 있다. 이를 2차원 배열로 reshape하여 확인해 보자.
```python
draw_fruits(km.cluster_centers_.reshape(-1, 100, 100), ratio=3)
```
![alt text](/assets/images/6-image-11.png)

**transform()**은 훈련데이터 샘플에서 각 Centroid까지의 거리를 반환한다.
참고로, 이 transform()은 2차원 배열을 input으로 기대하기에, 우리는 2차원 배열을 명시적으로 전달해야한다. 이를 위한 방법이 100번째 요소에 대해 알아보고 싶다면, [100]으로 인덱싱을 하는 것이 아니라, [100:101]로 슬라이싱한 값을 전달하는 것이다.
```python
print(km.transform(fruits_2d[100:101]))
#[[5267.70439881 8837.37750892 3393.8136117 ]]
```
레이블 2와의 거리가 가장 가까우므로, 아마 군집값 역시 2일 것이다.
```python
print(km.predict(fruits_2d[100:101]))
#[2]
```

참고로, k-means clustering은 위에 말했듯이 반복을 통해 최적 클러스터를 찾는다. 이때 반복횟수는 n_iter_ 속성에 저장된다.
```python
print(km.n_iter_)
#4
```

### 2-3. 최적의 k값 찾기

문제는 우리는 과일이 최소한 3가지 군집으로 나누어진다는 정보를 사용했다는 것이다. 실제 비지도 학습에서는 이 정보조차 주어지지 않는다. 그렇다면 몇 개의 군집으로 나눌지, 그 k는 어떻게 알 수 있을까?

우리는 **엘보우**라는 방식을 활용할 것이다. 앞서 언급한 Centroid와 샘플 간의 거리 제곱 합을 **이너셔(Inertia)**라고 부르는데, 군집 갯수가 늘어나면 당연히 이너셔는 줄어들 것이다. 이 k개수에 따른 이너셔의 변화를 관찰해 최적 k를 찾는것이 엘보우이다.

이너셔는 다시말하면 클러스터에 밀집된 정도이다. 그렇다면 다시 말해 이너셔가 크게 개선이 되지 않는다는 것은 밀집이 더 이상 잘안된다는 것이다. 우리는 그 변화폭이 생기는 지점을 찾는 것이다.

```python
inertia = []
for k in range(2, 7):
    km = KMeans(n_clusters=k, n_init='auto', random_state=42)
    km.fit(fruits_2d)
    inertia.append(km.inertia_)

plt.plot(range(2, 7), inertia)
plt.xlabel('k')
plt.ylabel('inertia')
plt.show()
```
![alt text](/assets/images/6-image-12.png)

대략적으로, 명확하지 않게 제시되긴 하지만 위의 예시에서는 3이라는 것을 알 수 있다.

## 3. 주성분 분석(PCA)

### 3-1. 차원 축소
차원은 굉장히 중요한 문제이다. 차원은 다른 말로 feature이다. 우리가 여태 활용한 그 feature와 같은 말이다. 우리는 차원을 축소할 것이다. **차원 축소**를 통해 과대 적합과 성능 개선을 기대할 수 있기 때문이다.

주성분 분석은 분산이 큰 방향을 찾는 것이다. 분산이 크다는 것은 데이터를 넓게 표현해준다는 의미이기 때문이다.
![alt text](/assets/images/6-image-13.png)

여기에서는 (2,1)이라는 벡터가 가장 데이터의 분산을 크게 설명하지 않는가?   
바로 이 벡터를 주성분이라고 부른다. 주성분 벡터는 요소가 2개로 원래 데이터의 차원과 동일하지만, 중요한 점은 이 주성분 축을 이용해 원래 데이터의 차원은 축소가 가능하다는 것이다.
![alt text](/assets/images/6-image-14.png)

S를 주성분 축에 투영하면 S는 1차원의 점으로 표현할 수 있기 때문이다.

![alt text](/assets/images/6-image-15.png)

마지막으로 주성분 축에 대해  수직이고 분산이 가장 큰 다음 방향을 찾으면 그게 두번째 주성분이다. 여기서는 2차원이기 때문에 하나의 두번째 주성분 방향이 나온다. 두번째 주성분을 찾는 이유는 첫번째 주성분만으로 불충분할 경우를 위함이다.

### 3-2. PCA 구현
```python
import numpy as np

fruits = np.load('fruits_300.npy')
fruits_2d = fruits.reshape(-1, 100*100)
from sklearn.decomposition import PCA

pca = PCA(n_components=50)
pca.fit(fruits_2d)
```
sklearn을 통해 PCA를 구현해보자. n_components를 통해 주성분 개수를 지정해야 한다.
```python
print(pca.components_.shape)
(50, 10000)
```
실제로 50개로 주성분이 나온 것을 확인할 수 있다. 실제로 주성분 50개로 축소 후의 이미지들을 확인해 보자.   

**이 이미지는 원래 있던 300개의 이미지가 줄어든것이 아니다!**   
이는 주성분, 즉 이미지들을 잘 설명하는 50가지 패턴 혹은 특징의 시각화이다.   
(50,10000)의 의미가 일반적인 2차원 배열의 의미가 아니라, 50개의 주성분을 통해 10000차원을 설명하고 있다고 이해하면 적절하다.
```python
draw_fruits(pca.components_.reshape(-1, 100, 100))
```
![alt text](/assets/images/6-image-16.png)

이제 원래 300개의 데이터를 pca의 tranform() 통해 50개의 차원으로 줄여보자.
```python
fruits_pca = pca.transform(fruits_2d)
print(fruits_pca.shape)
#(300, 50)
```
이를 통해 성공적으로 데이터를 1/200으로 줄일 수 있다!

### 3-3. 복원과 분산

축소한 차원을 원래대로 복원하는 것 역시 가능하다. inverse_tranform()을 활용하자.
```python
fruits_inverse = pca.inverse_transform(fruits_pca)
print(fruits_inverse.shape)
#(300, 10000)
```
```python
for start in [0, 100, 200]:
    draw_fruits(fruits_reconstruct[start:start+100])
    print("\n")
```
![alt text](/assets/images/6-image-17.png)

이미지들이 50개로 줄었다가 다시 10000개로 늘려졌음에도, 높은 복원률을 보여준다.

주성분이 데이터의 분산을 얼마나 잘 설명하는지를 **설명된 분산**이라고 한다. 이는 PCA클래스의 explained_variance_ratio_에 저장되어 있다.   
이 값들을 전부 더하면, 전체 주성분들이 데이터를 얼마나 잘 설명해주는지 확인할 수 있다. 또한 시각화를 통해 각각의 주성분이 얼마나 설명에 기여하는지 역시도 이해할 수 있다.
```python
print(np.sum(pca.explained_variance_ratio_))
#0.9215651897863715
plt.plot(pca.explained_variance_ratio_)
```
![alt text](/assets/images/6-image-18.png)

### 3-4. 지도학습에 적용

그렇다면 PCA를 지도학습인 로지스틱 회귀에 적용시켜 보도록 하겠다.
```python
from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
target = np.array([0] * 100 + [1] * 100 + [2] * 100)

from sklearn.model_selection import cross_validate

scores = cross_validate(lr, fruits_2d, target)
print(np.mean(scores['test_score']))
print(np.mean(scores['fit_time']))
#1.0
#0.032833099365234375
```
cross_validate(교차 점증)의 test_score을 통해 점수를, fit_time을 통해 훈련시간을 나타낸다. 아마 fit_time이 낮다면 그것은 모델이 더 경량하다는 것을 의미할 것이다.

아래는 PCA를 거친 결과이다.
```python
pca = PCA(n_components=0.5)
pca.fit(fruits_2d)
print(pca.n_components_)
#2
fruits_pca = pca.transform(fruits_2d)
print(fruits_pca.shape)
#(300, 2)
```
여기서 n_components에 비율이 들어가있는데, 정수를 입력하면 주성분의 개수를 정의하지만, 비율이 들어갈 경우, 그 만큼의 분산을 설명할 수 있는 주성분의 개수를 찾게 된다. 즉 여기서는 50%를 설명해줄수있을 만큼의 주성분 개수를 지정한 것이다. 2개의 주성분이 찾아진 것을 볼 수 있다!
```python
scores = cross_validate(lr, fruits_pca, target)
print(np.mean(scores['test_score']))
print(np.mean(scores['fit_time']))
#0.9933333333333334
#0.03713240623474121
```
차원 축소 후, 정확도가 99%로 개선되고 fit_time 역시 감소한 것을 확인할 수 있다!

또한 차원이 2개로 축소됨에 따라 얻을 수 있는 이점이 있는데, 바로 2차원으로 클러스터링의 시각화가 가능하다는 것이다! 만약 10000개라면 시각화할 수 없지 않겠는가?
```python
for label in range(0, 3):
    data = fruits_pca[km.labels_ == label]
    plt.scatter(data[:,0], data[:,1])
plt.legend(['apple', 'banana', 'pineapple'])
plt.show()
```
![alt text](/assets/images/6-image-19.png)