---
layout: post
title:  "5. 트리 알고리즘"
date:   2024-08-20 00:57:30 +09:00
categories: ['ML기초세션']
---
## 1. 결정 트리

결정 트리에 대해 들어가기 앞서, 로지스틱 회귀를 통해 임의의 와인 데이터를 가져와 와인 분류를 해보겠다. 
```python
import pandas as pd

wine = pd.read_csv('https://bit.ly/wine_csv_data')
data = wine[['alcohol', 'sugar', 'pH']].to_numpy()
target = wine['class'].to_numpy()

from sklearn.model_selection import train_test_split

train_input, test_input, train_target, test_target = train_test_split(
    data, target, test_size=0.2, random_state=42)

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(train_input)

train_scaled = ss.transform(train_input)
test_scaled = ss.transform(test_input)

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
lr.fit(train_scaled, train_target)

print(lr.score(train_scaled, train_target))
print(lr.score(test_scaled, test_target))
#0.7808350971714451
#0.7776923076923077
```
생각보다 낮은 정확도를 보여주는 것을 알 수 있다.   
참고로, LogisticRegression의 solver라는 매개변수는 사용할 알고리즘을 선택하는 것이다.    
(lbfgs, sag, saga 등이 존재한다)

여기서 의문이 든다. 만약에 도메인 관계자에게 이 로지스틱 회귀 분석을 통한 결과를 어떻게 설명할 것인가?   
기울기, 절편, 규제, 로지스틱 함수를 전부 설명할 것인가?   
그렇게 한다 한들 관계자가 직관적으로 이 분석의 이유를 납득할 수 있을까?

### 1-1. 결정 트리

**결정 트리(Decision Tree)**는 이 문제를 해결할 수 있다.    
가장 흔한 비유는 결정 트리는 스무 고개라는 것이다. 여러번의 질문을 통해 정답을 맞추어 나가는 것이다. 굉장히 직관적인 알고리즘이기에 당연히 남들에게 설명할 때에도 좋다!

![alt text](/assets/images/5-image.png)

```python
from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier(random_state=42)
dt.fit(train_scaled, train_target)

print(dt.score(train_scaled, train_target))
print(dt.score(test_scaled, test_target))
#0.996921300750433
#0.8592307692307692
```

위의 와인 데이터를 불러와 결정 트리로 예측한 것이다. 이 역시 sklearn에서 import 가능하다.
그렇다면 어떤 트리를 거쳐서 이 결과가 만들어 졌을까? plot_tree라는 메서드를 통해 확인가능하다.
```python
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

plt.figure(figsize=(10,7))
plot_tree(dt)
plt.show()
```
![alt text](/assets/images/5-image-1.png)

위의 사진이 실제로 방금의 fit을 통해 만들어진 트리이다. 우리는 이러한 트리에서 각 점을 노드라고 부르고, 가장 위의 노드를 루트 노드, 가장 끝의 노드를 리프 노드라고 부른다.
```python
plt.figure(figsize=(10,7))
plot_tree(dt, max_depth=1, filled=True, feature_names=['alcohol', 'sugar', 'pH'])
plt.show()
```
여기서 plot_tree의 매개변수를 수정하면 조금 더 많은 정보를 확인할 수 있다.   
아래의 노드에 표시된 상세 정보는 직관적으로 이해가 되니 생략하고, 위에서 사용된 파라미터에 대해 알아보자.
- max_depth: 어느 깊이까지 트리를 나타낼 지 정함
- filled: 어떤 클래스의 비율이 높아짐에 따라 색의 진함으로 나타냄

따라서 아래에서는 처음에는 1258:3939로 양성이 우세한것에 더해, 오른쪽 노드는 그 편차가 더 심해졌으므로 더 진한 파란색으로 표시가 된 것이다. 
![alt text](/assets/images/5-image-2.png)

### 1-2. 불순도

위에서 gini라고 표시된 것은 **지니 불순도**를 의미한다. 참고로 DeicisionTreeClassifier의 기본 criterion 매개변수 값은 gini이다. 지니 불순도는 말그대로 얼마나 지금 노드에 담긴 데이터들이 불순한지를 나타낸 것이다. 따라서 압도적으로 양성이 많은 오른쪽 노드가 그렇지 않은, 혼탁한 왼쪽 노드보다 낮은 gini 계수를 가지는 것이다.

이는 직관적인 설명이고, 아래가 명확한 지니 불순도의 수식이다.

![alt text](/assets/images/5-image-3.png)

지니 불순도는 0에서 0.5 사이의 값을 가지며, 0일때 순수한 **순수 노드** 상태이고, 정확히 절반씩 클래스가 존재한다면 가장 혼돈이 극심한 0.5이다.

**이를 반영해, 트리는 부모노드와 자식노드 사이의 불순도 차이를 극대화 하는 방식으로 성장한다.**   
아래는 위의 샘플을 예시로 구현한 **정보 이득(Information Gain)** 이다. 정보 이득이 위에 말한 불순도 차이이다.
![alt text](/assets/images/5-image-4.png)

지니 불순도 외에도 criterion에는 entropy라는 불순도 기준도 존재한다. 수식은 로그를 사용한다는 점에서 지니 불순도와 차이가 있다. 하지만 혼돈(불순도)를 나타낸다는 점에서 동일하다.
![alt text](/assets/images/5-image-5.png)

### 1-3. 가지치기

그렇다면 다시 돌아가서, 질문을 많이 하는 트리가 좋은 트리일까?   
당연히 아니다. 직관적으로 생각해도 오버피팅 문제가 생길 것 같지 않은가?

이럴 때 가지치기가 필요하다. 이제부터 가지를 치는 방법을 알아보자.

그 방법은 바로 깊이(max_depth)를 제한하는 것이다.
```python
dt = DecisionTreeClassifier(max_depth=3, random_state=42)
dt.fit(train_scaled, train_target)

print(dt.score(train_scaled, train_target))
print(dt.score(test_scaled, test_target))
#0.8454877814123533
#0.8415384615384616
```
![alt text](/assets/images/5-image-6.png)

깊이를 3으로 제한하니 훨씬 깔끔한 트리가 만들어졌다!  
또한 훈련 세트 성능은 조금 감소했지만 테스트 성능은 거의 그대로인 것을 확인할 수 있다.

참고로, 위의 트리에는 당도가 음수로 표현되어있는데, 이는 우리가 학습 시에 스케일링이 완료된 데이터를 넣어서 그렇다. 의사결정나무에서 스케일링은 중요하지 않다. 따라서 스케일링을 거치지 않은 원시 데이터를 넣어도 동일한 결과를 얻을 수 있다.

마지막으로, 이 트리에서 어떤 특성이 가장 요긴하게 사용되었는지를 확인할 수 있다.
```python
print(dt.feature_importances_)
#[0.12345626 0.86862934 0.0079144 ]
```
두번째 특성이 가장 잘 쓰였다는 것을 확인할 수 있다!

## 2. 교차 검증과 그리드 서치

직관적으로 생각해보자. 우리가 테스트 세트로 검증을 하는 것도 여러번 하면 결국 테스트 셋에 모델을 피팅하게 되버리지 않을까? 테스트 셋의 의미가 퇴색되어 버린다는 것이다.

이를 위해 우리는 훈련 셋의 일부를 떼어내어 **검증 세트(Validation Set)** 을 만들 수 있다.

![alt text](/assets/images/5-image-7.png)

검증 세트를 떼어서 테스트를 진행하기에 검사의 불안정성이 높아졌다. 왜냐하면 가뜩이나 없는 훈련 세트를 쪼개서 검증 세트를 만들었기 때문이다.

### 2-1. 교차 검증
**교차 검증**이란 검증 세트를 떼어내고 평가하는 과정을 여러번 반복하여 평균을 내는 것이다. 이렇게 할 경우에는 더 안정적인 검증 점수를 얻고 훈련에 더 많은 데이터를 사용할 수 있다. 아래는 그 방법중 하나인 3-폴드 교차 검증이다.

![alt text](/assets/images/5-image-8.png)

이렇게 서로 다른 부분을 여러번 떼어내서 여러번 검증한다면 좀 더 유의미해지지 않겠는가?
```python
from sklearn.model_selection import cross_validate

scores = cross_validate(dt, train_input, train_target)
print(scores)
#{'fit_time': array([0.00931716, 0.00749564, 0.00773239, 0.00731683, 0.00710797]), 'score_time': array([0.00109315, 0.00111032, 0.00101209, 0.00106931, 0.00115085]), 'test_score': array([0.86923077, 0.84615385, 0.87680462, 0.84889317, 0.83541867])}
```

cross_validate()을 통해 교차 검증이 가능한데, 기본적으로 5-폴드 교차 검증을 수행한다.     
참고로 폴드 수는 cv매개변수를 통해 수정가능하다.   
test score에 담긴 점수가 각 검증 폴드에서 얻어진 점수이다. 따라서 이를 평균내면 된다.
```python
import numpy as np

print(np.mean(scores['test_score']))
#0.855300214703487
```
여기서 중요한 점 하나를 짚고 가자.    
**cross_validate()는 훈련 세트를 섞지 않는다.**

지금 상황에서는 train_test_split()을 통해 섞인 훈련 세트를 전달했지만, 일반적인 상황에서는 자동으로 섞이지 않기 때문에 분할기를 지정해주어야 한다.
- 회귀모델에 적용할 경우: KFold
- 분류모델에 적용할 경우: StratifiedKFold

```python
from sklearn.model_selection import StratifiedKFold

scores = cross_validate(dt, train_input, train_target, cv=StratifiedKFold())
print(np.mean(scores['test_score']))
#0.855300214703487
```

그런데 이상하지 않은가? 분명 cv매개변수는 폴드 수를 지정한다고 했는데, 왜 객체가 저기에 들어가는 것일까?
> cv에 숫자 값을 지정하면 기본적인 K-Fold 교차 검증에서 사용할 폴드 수를 나타냅니다. 예를 들어, cv=5는 5개의 폴드로 교차 검증을 수행한다는 의미이지만, 객체를 지정할 경우, 예를 들어 StratifiedKFold, cv는 폴드 생성 방식을 정의하는 객체를 전달받아 그 객체의 설정에 따라 교차 검증을 수행한다.

만약 훈련 세트를 섞은 후 폴드 수를 수정하고 싶다면, 분류기의 n_splits 파라미터를 조정하면 된다.
```python
splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
scores = cross_validate(dt, train_input, train_target, cv=splitter)
print(np.mean(scores['test_score']))
#0.8574181117533719
```

### 2-2. 하이퍼파라미터 튜닝
사용자가 지정하는 파라미터를 하이퍼파라미터라고 했다.   
하이퍼파라미터 튜닝이란, 이 매개변수들을 동시에 튜닝해 최적의 값을 찾는 것을 말한다.
이를 위해 **그리드 서치(Grid Search)** 를 이용한다.

```python
from sklearn.model_selection import GridSearchCV

params = {'min_impurity_decrease': [0.0001, 0.0002, 0.0003, 0.0004, 0.0005]}
gs = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1)
gs.fit(train_input, train_target)
dt = gs.best_estimator_
print(dt.score(train_input, train_target))
#0.9615162593804117
```

과정은 아래와 같다.   
1. 시도할 파라미터를 딕셔너리 형태로 만든다
2. GridSearchCV 객체에 할당한다.
3. gs 객체를 학습시킨다.
4. 최적의 파라미터로 학습된 모델을 .best_estimator_로 확인한다.

이때, GridSearchCV는 하이퍼파라미터 탐색과 더불어 교차 검증이 함께 수행되므로 편리하다. 즉 cross_validate()를 사용하지 않아도 된다. 참고로 n_jobs는 사용할 CPU의 개수이다.

```python
print(gs.best_params_)
#{'min_impurity_decrease': 0.0001}
print(gs.cv_results_['mean_test_score'])
#[0.86819297 0.86453617 0.86492226 0.86780891 0.86761605]
```
최적의 파라미터 값과 각 파라미터 별 교차 검증 값도 위와 같이 확인 가능하다.

우리의 원래 목적은 여러개의 파라미터를 한번에 고려하는 것이었다.
```python
params = {'min_impurity_decrease': np.arange(0.0001, 0.001, 0.0001),
          'max_depth': range(5, 20, 1),
          'min_samples_split': range(2, 100, 10)
          }
gs = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1)
gs.fit(train_input, train_target)
print(gs.best_params_)
#{'max_depth': 14, 'min_impurity_decrease': 0.0004, 'min_samples_split': 12}
print(np.max(gs.cv_results_['mean_test_score']))
#0.8683865773302731
```
위의 경우는 총 1350개의 파라미터 경우의 수, 5번의 폴드 수로 6750번의 경우를 연산한다.

```python
print(gs.best_params_)
#{'max_depth': 14, 'min_impurity_decrease': 0.0004, 'min_samples_split': 12}
```

이 역시 최적의 파라미터가 위와 같은 것을 확인할 수 있다.

### 2-3. 랜덤 서치
위의 그리드 서치의 단점은, 파라미터 범위 및 간격을 정하기 애매하다는 것과 연산량에 따른 시간이 오래걸린다는 것이다.

이를 위한 것이 **랜덤 서치**이다. 직접 매개변수 값을 주는 것이 아니라, 매개변수의 확률분포를 전달한다.

```python
from scipy.stats import uniform, randint
params = {'min_impurity_decrease': uniform(0.0001, 0.001),
          'max_depth': randint(20, 50),
          'min_samples_split': randint(2, 25),
          'min_samples_leaf': randint(1, 25),
          }
```
만약 scipy를 통해 위와 같이 전달했다고 하면, uniform을 통해 실수값을, randint를 통해 정수값을 전달하는 것이다.

```python
from sklearn.model_selection import RandomizedSearchCV

gs = RandomizedSearchCV(DecisionTreeClassifier(random_state=42), params,
                        n_iter=100, n_jobs=-1, random_state=42)
gs.fit(train_input, train_target)
```
위와 같이 n_iter를 100으로 설정해 100번의 샘플링을 통해 최적의 조합을 찾아낸다.   
주어진 파라미터로 무작위 조합을 100번 시도한다는 것이다.
따라서 원래의 어마무시한 연산시도보다 효율적으로 탐색이 가능하다.

## 3. 앙상블

일반적으로 비정형 데이터는 신경망 알고리즘으로, 정형 데이터는 머신러닝 알고리즘을 사용한다.   
이때 가장 뛰어난 성과를 내는 것이 **앙상블 학습**이다.

### 3-1. 랜덤 포레스트
랜덤 포레스트는 Decision Tree 여러 개의 숲을 만든다음 그 숲에서 최선의 결과를 만들어내는 것이다.
이때 각 나무를 훈련하기 위해 훈련 데이터에서 랜덤하게 샘플을 뽑는데, 이때 **부트스트랩 샘플**이 이용된다. 예를 들어 1000개의 데이터가 있으면 1000개의 샘플을 복원 추출로 뽑는것이다.

![alt text](/assets/images/5-image-9.png)

또한 각 나무들은 전체 특성을 이용해 분류를 하는 것이 아니라, 일부만 무작위로 사용한다. RandomForestClassifier의 경우, 전체 특성의 제곱근만큼의 특성을 선택한다. 즉 4개의 특성이 있다면 2개만 사용한다는 것이다.단, RandomForestRegressor의 경우 전체 특성을 이용한다.

sklearn의 랜덤 포레스트는 100개의 결정트리를 훈련한다. 그 다음 분류일 때는 각 트리의 클래스별 확률을 평균하여 가장 높은 확률을 가진 클래스를 예측으로 삼고, 회귀일 때는 단순히 각 트리의 예측을 평균한다.

```python
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

wine = pd.read_csv('https://bit.ly/wine_csv_data')

data = wine[['alcohol', 'sugar', 'pH']].to_numpy()
target = wine['class'].to_numpy()

train_input, test_input, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state=42)

from sklearn.model_selection import cross_validate
from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(n_jobs=-1, random_state=42)
scores = cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs=-1)

print(np.mean(scores['train_score']), np.mean(scores['test_score']))
#0.9973541965122431 0.8905151032797809
```
return_train_score를 True로 설정하면 검증점수 뿐 아니라 훈련세트에 대한 점수도 반환해준다! 기본값은 False이다.

```python
rf.fit(train_input, train_target)
print(rf.feature_importances_)
#[0.23167441 0.50039841 0.26792718]
```
랜덤 포레스트도 동일하게 특성중요도를 확인할 수 있는데, 보면 원래 단일 결정트리의 중요도와는 조금 다른것을 확인할 수 있다. 이 이유는 랜덤 포레스트가 특성을 무작위로 선택하기에 더 많은 특성이 훈련에 참여할 기회를 얻기 때문이다.

그리고 OOB(Out of Bag)이라는 것이 있는데, 부트스트랩이 중복을 허용해 샘플을 뽑기에 뽑히지 않고 남는 샘플 하나가 있다. 이것을 가지고 모델의 성능을 테스트 할 수 있다.
```python
rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)

rf.fit(train_input, train_target)
print(rf.oob_score_)
#0.8934000384837406
```

### 3-2. 엑스트라 트리
엑스트라 트리는 랜덤 포레스트와 유사하지만 부트스트랩을 사용하지 않는다.   
대신 노드를 분할할 때 무작위로 분할한다. DecisionTreeClassifier의 splitter 매개변수가 random인 나무들로 이루어진 숲인 것이다.

하나의 트리에서 이렇게 한다면 성능이 낮아지겠지만, 많은 트리를 앙상블 하기에 과대적합을 막고 검증 세트의 점수를 높이는 효과가 있다.
```python
from sklearn.ensemble import ExtraTreesClassifier

et = ExtraTreesClassifier(n_jobs=-1, random_state=42)
scores = cross_validate(et, train_input, train_target, return_train_score=True, n_jobs=-1)

print(np.mean(scores['train_score']), np.mean(scores['test_score']))
#0.9974503966084433 0.8887848893166506

et.fit(train_input, train_target)
print(et.feature_importances_)
#[0.20183568 0.52242907 0.27573525]
```
엑스트라 트리는 랜덤으로 진행되기에 계산 속도가 빠르다는 장점이 있다!   
그리고 ExtraTreesRegressor라는 회귀 버전 역시 존재한다.

### 3-3. 그라디언트 부스팅
**그라디언트 부스팅(Gradient Boosting)** 은 깊이가 얇은 결정 트리를 사용하여 이진 트리의 오차를 보완하는 방식이다. 깊이가 3, 트리 개수 100개가 기본이다. 깊이가 얕기에 과대적합에 강하고 일반적으로 높은 일반화 성능을 기대할 수 있다.

그라디언트, 즉 기울기에 관한 모델인데, 따라서 트리를 계속 추가하면서 가장 낮은 곳으로 이동하는 방식이다. 로스 함수를 계산하고 최소화 하는 방향으로 갱신된다.
```python
from sklearn.ensemble import GradientBoostingClassifier

gb = GradientBoostingClassifier(random_state=42)
scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)

print(np.mean(scores['train_score']), np.mean(scores['test_score']))
#0.8881086892152563 0.8720430147331015
```

또한 그라디언트 부스팅은 트리 개수를 늘려도 과적합이 잘 일어나지 않는다. 학습률을 증가시키고 트리의 개수를 늘리면 성능 향상을 유도할 수 있다.

참고로 subsample이라는 매개변수가 존재하는데, 이는 기본값 1, 전체 훈련 세트 사용이지만 확률적 경사하강법 처럼 이 수치를 조정해 일부 세트만 활용할 수도 있다.

### 3-4. 히스토그램 기반 그라디언트 부스팅
입력 특성을 256 구간으로 나누고 시작하기 때문에 최적의 분할을 빠르게 찾을 수 있다.   
또한 성능과 관련해 트리의 개수인 n_estimators 대신에 부스팅 반복 횟수인 max_iter를 사용한다.
```python
from sklearn.ensemble import HistGradientBoostingClassifier

hgb = HistGradientBoostingClassifier(random_state=42)
scores = cross_validate(hgb, train_input, train_target, return_train_score=True, n_jobs=-1)

print(np.mean(scores['train_score']), np.mean(scores['test_score']))
#0.9321723946453317 0.8801241948619236
```

이외에도 XGBoost, LightGBM 등의 히스토그램 그라디언트 부스팅 기반의 라이브러리가 존재한다.